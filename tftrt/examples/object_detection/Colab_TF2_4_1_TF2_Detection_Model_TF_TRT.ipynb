{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Colab_TF2.4.1_TF2_Detection_Model_TF_TRT.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pc_vd2GuXtv0"
      },
      "source": [
        "# TF-TRT Inference from TensorFlow 2 Detection Model \n",
        "\n",
        "\n",
        "## Introduction\n",
        "This notebook demonstrates the process of creating and benchmarking a TF-TRT optimization model from a TensorFlow 2 Detection Model Zoo model.\n",
        "\n",
        "## Requirement\n",
        "\n",
        "### GPU\n",
        "\n",
        "Before running this notebook, please set the Colab runtime environment to GPU via the menu *Runtime => Change runtime type => GPU*.\n",
        "\n",
        "This demo will work on any NVIDIA GPU with CUDA cores, though for improved FP16 and INT8 inference, a Volta, Turing or newer generation GPU with Tensor cores is desired.  On Google Colab, this normally means a T4 GPU. If you are assigned an older K80 GPU, another trial at another time might give you a T4 GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7hSyfxhpzh5"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTLvVhNNFIIg"
      },
      "source": [
        "!cat /proc/cpuinfo"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1eXqJLeFNWQ"
      },
      "source": [
        "!cat /proc/meminfo"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjrBA2KwEpfI"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCioiVpSTE05"
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "import csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nt-yb65nJYeY"
      },
      "source": [
        "output_drive_path = \"/content/drive/MyDrive/result.csv\"\n",
        "output_path = \"/content/result.csv\"\n",
        "\n",
        "if os.path.exists(output_drive_path):\n",
        "    print(\"The result.csv file exists.\")\n",
        "    shutil.copyfile(output_drive_path, output_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wMll2pqIgbWu"
      },
      "source": [
        "### Install TensorFlow 2.4.1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "dGmA4AZogbEB"
      },
      "source": [
        "%%bash\n",
        "pip uninstall -y tensorflow\n",
        "pip install tensorflow==2.4.1\n",
        "# pip install tf-nightly"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WdfSdjXrZA5-"
      },
      "source": [
        "### Install TensorRT Runtime"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-aSfAox3qAsz"
      },
      "source": [
        "%%bash\n",
        "apt-get update\n",
        "apt-get install -y --no-install-recommends \\\n",
        "    libnvinfer7=7.1.3-1+cuda11.0 \\\n",
        "    libnvinfer-dev=7.1.3-1+cuda11.0 \\\n",
        "    libnvinfer-plugin7=7.1.3-1+cuda11.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ox5PQEm2YxJ4"
      },
      "source": [
        "### Check the version of TensorFlow-GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "EJha5ioNqGCs"
      },
      "source": [
        "# check TensorRT version\n",
        "print(\"TensorRT version: \")\n",
        "!dpkg -l | grep nvinfer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "BJYE-rY2p41I"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.compiler.tf2tensorrt._pywrap_py_utils import is_tensorrt_enabled\n",
        " \n",
        "print(\"Tensorflow version: \", tf.version.VERSION)\n",
        "print(\"TensorRT enabled  : \", is_tensorrt_enabled())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oN2JEQehZ4HV"
      },
      "source": [
        "### Check Tensor core GPU\n",
        "The below code check whether a Tensor-core GPU is present."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "v_tq5ApGqOZE"
      },
      "source": [
        "from tensorflow.python.client import device_lib\n",
        " \n",
        "def check_tensor_core_gpu_present():\n",
        "    local_device_protos = device_lib.list_local_devices()\n",
        "    for line in local_device_protos:\n",
        "        if \"compute capability\" in str(line):\n",
        "            compute_capability = float(line.physical_device_desc.split(\"compute capability: \")[-1])\n",
        "            if compute_capability>=7.0:\n",
        "                return True\n",
        "    \n",
        "print(\"Tensor Core GPU Present:\", check_tensor_core_gpu_present())\n",
        "tensor_core_gpu = check_tensor_core_gpu_present()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bs7PqdOfhYFP"
      },
      "source": [
        "### Download COCO Val 2017 Dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Be_qiP2qhm91"
      },
      "source": [
        "%%bash\n",
        "\n",
        "wget http://images.cocodataset.org/zips/val2017.zip\n",
        "unzip -q val2017.zip\n",
        "wget http://images.cocodataset.org/annotations/annotations_trainval2017.zip\n",
        "unzip -q annotations_trainval2017.zip\n",
        "rm -r val2017.zip annotations_trainval2017.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9bXQHZwZ8Oc"
      },
      "source": [
        "### Clone the required repository."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "JobnA0I0aE2D"
      },
      "source": [
        "%%bash\n",
        "\n",
        "git clone -b detection2 https://github.com/NobuoTsukamoto/tensorrt.git\n",
        "cd tensorrt/tftrt/examples/object_detection\n",
        "git submodule update --init\n",
        "/content/tensorrt/tftrt/examples/object_detection/install_dependencies.sh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I91buLRjbRfo"
      },
      "source": [
        "### Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "66yZCLPgq9p_"
      },
      "source": [
        "MODELS = {\n",
        "    \"centernet_hg104_512x512_coco17_tpu\": {\n",
        "        \"name\": \"CenterNet\\ HourGlass104\",\n",
        "        \"input\": (512, 512),\n",
        "        \"extract_dir\": \"centernet_hg104_512x512_coco17_tpu-8\",\n",
        "        \"url\": \"http://download.tensorflow.org/models/object_detection/tf2/20200713/centernet_hg104_512x512_coco17_tpu-8.tar.gz\",\n",
        "    },\n",
        "    \"centernet_hg104_512x512_kpts_coco17_tpu\": {\n",
        "        \"name\": \"CenterNet\\ HourGlass104\\ Keypoints\",\n",
        "        \"input\": (512, 512),\n",
        "        \"extract_dir\": \"centernet_hg104_512x512_kpts_coco17_tpu-32\",\n",
        "        \"url\": \"http://download.tensorflow.org/models/object_detection/tf2/20200711/centernet_hg104_512x512_kpts_coco17_tpu-32.tar.gz\",\n",
        "    },\n",
        "    \"centernet_hg104_1024x1024_coco17_tpu\": {\n",
        "        \"name\": \"CenterNet\\ HourGlass104\",\n",
        "        \"input\": (1024, 1024),\n",
        "        \"extract_dir\": \"centernet_hg104_1024x1024_coco17_tpu-32\",\n",
        "        \"url\": \"http://download.tensorflow.org/models/object_detection/tf2/20200713/centernet_hg104_1024x1024_coco17_tpu-32.tar.gz\",\n",
        "    },\n",
        "    \"centernet_hg104_1024x1024_kpts_coco17_tpu\": {\n",
        "        \"name\": \"CenterNet\\ HourGlass104\\ Keypoints\",\n",
        "        \"input\": (1024, 1024),\n",
        "        \"extract_dir\": \"centernet_hg104_1024x1024_kpts_coco17_tpu-32\",\n",
        "        \"url\": \"http://download.tensorflow.org/models/object_detection/tf2/20200711/centernet_hg104_1024x1024_kpts_coco17_tpu-32.tar.gz\",\n",
        "    },\n",
        "    \"centernet_resnet50_v1_fpn_512x512_coco17_tpu\": {\n",
        "        \"name\": \"CenterNet\\ Resnet50\\ V1\\ FPN\",\n",
        "        \"input\": (512, 512),\n",
        "        \"extract_dir\": \"centernet_resnet50_v1_fpn_512x512_coco17_tpu-8\",\n",
        "        \"url\": \"http://download.tensorflow.org/models/object_detection/tf2/20200711/centernet_resnet50_v1_fpn_512x512_coco17_tpu-8.tar.gz\",\n",
        "    },\n",
        "    \"centernet_resnet50_v1_fpn_512x512_kpts_coco17_tpu\": {\n",
        "        \"name\": \"CenterNet\\ Resnet50\\ V1\\ FPN\\ Keypoints\",\n",
        "        \"input\": (512, 512),\n",
        "        \"extract_dir\": \"centernet_resnet50_v1_fpn_512x512_kpts_coco17_tpu-8\",\n",
        "        \"url\": \"http://download.tensorflow.org/models/object_detection/tf2/20200711/centernet_resnet50_v1_fpn_512x512_kpts_coco17_tpu-8.tar.gz\",\n",
        "    },\n",
        "    \"centernet_resnet101_v1_fpn_512x512_coco17_tpu\": {\n",
        "        \"name\": \"CenterNet\\ Resnet101\\ V1\\ FPN\",\n",
        "        \"input\": (512, 512),\n",
        "        \"extract_dir\": \"centernet_resnet101_v1_fpn_512x512_coco17_tpu-8\",\n",
        "        \"url\": \"http://download.tensorflow.org/models/object_detection/tf2/20200711/centernet_resnet101_v1_fpn_512x512_coco17_tpu-8.tar.gz\",\n",
        "    },\n",
        "    \"centernet_resnet50_v2_512x512_coco17_tpu\": {\n",
        "        \"name\": \"CenterNet\\ Resnet50\\ V2\",\n",
        "        \"input\": (512, 512),\n",
        "        \"extract_dir\": \"centernet_resnet50_v2_512x512_coco17_tpu-8\",\n",
        "        \"url\": \"http://download.tensorflow.org/models/object_detection/tf2/20200711/centernet_resnet50_v2_512x512_coco17_tpu-8.tar.gz\",\n",
        "    },\n",
        "    \"centernet_resnet50_v2_512x512_kpts_coco17_tpu\": {\n",
        "        \"name\": \"CenterNet\\ Resnet50\\ V2\\ Keypoints\",\n",
        "        \"input\": (512, 512),\n",
        "        \"extract_dir\": \"centernet_resnet50_v2_512x512_kpts_coco17_tpu-8\",\n",
        "        \"url\": \"http://download.tensorflow.org/models/object_detection/tf2/20200711/centernet_resnet50_v2_512x512_kpts_coco17_tpu-8.tar.gz\",\n",
        "    },\n",
        "    \"centernet_mobilenetv2fpn_512x512_coco17_od\": {\n",
        "        \"name\": \"CenterNet\\ MobileNetV2\\ FPN\",\n",
        "        \"input\": (512, 512),\n",
        "        \"extract_dir\": \"centernet_mobilenetv2_fpn_od\",\n",
        "        \"url\": \"http://download.tensorflow.org/models/object_detection/tf2/20210210/centernet_mobilenetv2fpn_512x512_coco17_od.tar.gz\",\n",
        "    },\n",
        "    \"centernet_mobilenetv2fpn_512x512_coco17_kpts\": {\n",
        "        \"name\": \"CenterNet\\ MobileNetV2\\ FPN\\ Keypoints\",\n",
        "        \"input\": (512, 512),\n",
        "        \"extract_dir\": \"centernet_mobilenetv2_fpn_kpts\",\n",
        "        \"url\": \"http://download.tensorflow.org/models/object_detection/tf2/20210210/centernet_mobilenetv2fpn_512x512_coco17_kpts.tar.gz\",\n",
        "    },\n",
        "    \"efficientdet_d0_coco17_tpu\": {\n",
        "        \"name\": \"EfficientDet\\ D0\",\n",
        "        \"input\": (512, 512),\n",
        "        \"extract_dir\": \"efficientdet_d0_coco17_tpu-32\",\n",
        "        \"url\": \"http://download.tensorflow.org/models/object_detection/tf2/20200711/efficientdet_d0_coco17_tpu-32.tar.gz\",\n",
        "    },\n",
        "    \"efficientdet_d1_coco17_tpu\": {\n",
        "        \"name\": \"EfficientDet\\ D1\",\n",
        "        \"input\": (640, 640),\n",
        "        \"extract_dir\": \"efficientdet_d1_coco17_tpu-32\",\n",
        "        \"url\": \"http://download.tensorflow.org/models/object_detection/tf2/20200711/efficientdet_d1_coco17_tpu-32.tar.gz\",\n",
        "    },\n",
        "    \"efficientdet_d2_coco17_tpu\": {\n",
        "        \"name\": \"EfficientDet\\ D2\",\n",
        "        \"input\": (768, 768),\n",
        "        \"extract_dir\": \"efficientdet_d2_coco17_tpu-32\",\n",
        "        \"url\": \"http://download.tensorflow.org/models/object_detection/tf2/20200711/efficientdet_d2_coco17_tpu-32.tar.gz\",\n",
        "    },\n",
        "    \"efficientdet_d3_coco17_tpu\": {\n",
        "        \"name\": \"EfficientDet\\ D3\",\n",
        "        \"input\": (896, 896),\n",
        "        \"extract_dir\": \"efficientdet_d3_coco17_tpu-32\",\n",
        "        \"url\": \"http://download.tensorflow.org/models/object_detection/tf2/20200711/efficientdet_d3_coco17_tpu-32.tar.gz\",\n",
        "    },\n",
        "    \"efficientdet_d4_coco17_tpu\": {\n",
        "        \"name\": \"EfficientDet\\ D4\",\n",
        "        \"input\": (1024, 1024),\n",
        "        \"extract_dir\": \"efficientdet_d4_coco17_tpu-32\",\n",
        "        \"url\": \"http://download.tensorflow.org/models/object_detection/tf2/20200711/efficientdet_d4_coco17_tpu-32.tar.gz\",\n",
        "    },\n",
        "    \"efficientdet_d5_coco17_tpu\": {\n",
        "        \"name\": \"EfficientDet\\ D5\",\n",
        "        \"input\": (1280, 1280),\n",
        "        \"extract_dir\": \"efficientdet_d5_coco17_tpu-32\",\n",
        "        \"url\": \"http://download.tensorflow.org/models/object_detection/tf2/20200711/efficientdet_d5_coco17_tpu-32.tar.gz\",\n",
        "    },\n",
        "    \"efficientdet_d6_coco17_tpu\": {\n",
        "        \"name\": \"EfficientDet\\ D6\",\n",
        "        \"input\": (1280, 1280),\n",
        "        \"extract_dir\": \"efficientdet_d6_coco17_tpu-32\",\n",
        "        \"url\": \"http://download.tensorflow.org/models/object_detection/tf2/20200711/efficientdet_d6_coco17_tpu-32.tar.gz\",\n",
        "    },\n",
        "    \"efficientdet_d7_coco17_tpu\": {\n",
        "        \"name\": \"EfficientDet\\ D7\",\n",
        "        \"input\": (1536, 1536),\n",
        "        \"extract_dir\": \"efficientdet_d7_coco17_tpu-32\",\n",
        "        \"url\": \"http://download.tensorflow.org/models/object_detection/tf2/20200711/efficientdet_d7_coco17_tpu-32.tar.gz\",\n",
        "    },\n",
        "    \"ssd_mobilenet_v2_320x320_coco17_tpu\": {\n",
        "        \"name\": \"SSD\\ MobileNet\\ v2\",\n",
        "        \"input\": (320, 320),\n",
        "        \"extract_dir\": \"ssd_mobilenet_v2_320x320_coco17_tpu-8\",\n",
        "        \"url\": \"http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_320x320_coco17_tpu-8.tar.gz\",\n",
        "    },\n",
        "    \"ssd_mobilenet_v1_fpn_640x640_coco17_tpu\": {\n",
        "        \"name\": \"SSD\\ MobileNet\\ V1\\ FPN\",\n",
        "        \"input\": (640, 640),\n",
        "        \"extract_dir\": \"ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8\",\n",
        "        \"url\": \"http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8.tar.gz\",\n",
        "    },\n",
        "    \"ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu\": {\n",
        "        \"name\": \"SSD\\ MobileNet\\ V2\\ FPNLite\",\n",
        "        \"input\": (320, 320),\n",
        "        \"extract_dir\": \"ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8\",\n",
        "        \"url\": \"http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz\",\n",
        "    },\n",
        "    \"ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu\": {\n",
        "        \"name\": \"SSD\\ MobileNet\\ V2\\ FPNLite\",\n",
        "        \"input\": (640, 640),\n",
        "        \"extract_dir\": \"ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8\",\n",
        "        \"url\": \"http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8.tar.gz\",\n",
        "    },\n",
        "    \"ssd_resnet50_v1_fpn_640x640_coco17_tpu\": {\n",
        "        \"name\": \"SSD\\ ResNet50\\ V1\\ FPN\\ RetinaNet50\",\n",
        "        \"input\": (640, 640),\n",
        "        \"extract_dir\": \"ssd_resnet50_v1_fpn_640x640_coco17_tpu-8\",\n",
        "        \"url\": \"http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8.tar.gz\",\n",
        "    },\n",
        "    \"ssd_resnet50_v1_fpn_1024x1024_coco17_tpu\": {\n",
        "        \"name\": \"SSD\\ ResNet50\\ V1\\ FPN\\ RetinaNet50\", \n",
        "        \"input\": (1024, 1024), \n",
        "        \"extract_dir\": \"ssd_resnet50_v1_fpn_1024x1024_coco17_tpu-8\",\n",
        "        \"url\": \"http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_resnet50_v1_fpn_1024x1024_coco17_tpu-8.tar.gz\",\n",
        "    },\n",
        "    \"ssd_resnet101_v1_fpn_640x640_coco17_tpu\": {\n",
        "        \"name\": \"SSD\\ ResNet101\\ V1\\ FPN\\ RetinaNet101\",\n",
        "        \"input\": (640, 640),\n",
        "        \"extract_dir\": \"ssd_resnet101_v1_fpn_640x640_coco17_tpu-8\",\n",
        "        \"url\": \"http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_resnet101_v1_fpn_640x640_coco17_tpu-8.tar.gz\",\n",
        "    },\n",
        "    \"ssd_resnet101_v1_fpn_1024x1024_coco17_tpu\": {\n",
        "        \"name\": \"SSD\\ ResNet101\\ V1\\ FPN\\ RetinaNet101\",\n",
        "        \"input\": (1024, 1024),\n",
        "        \"extract_dir\": \"ssd_resnet101_v1_fpn_1024x1024_coco17_tpu-8\",\n",
        "        \"url\": \"http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_resnet101_v1_fpn_1024x1024_coco17_tpu-8.tar.gz\",\n",
        "    },\n",
        "    \"ssd_resnet152_v1_fpn_640x640_coco17_tpu\": {\n",
        "        \"name\": \"SSD\\ ResNet152\\ V1\\ FPN\\ RetinaNet152\",\n",
        "        \"input\": (640, 640),\n",
        "        \"extract_dir\": \"ssd_resnet152_v1_fpn_640x640_coco17_tpu-8\",\n",
        "        \"url\": \"http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_resnet152_v1_fpn_640x640_coco17_tpu-8.tar.gz\",\n",
        "    },\n",
        "    \"ssd_resnet152_v1_fpn_1024x1024_coco17_tpu\": {\n",
        "        \"name\": \"SSD\\ ResNet152\\ V1\\ FPN\\ RetinaNet152\",\n",
        "        \"input\": (1024, 1024),\n",
        "        \"extract_dir\": \"ssd_resnet152_v1_fpn_1024x1024_coco17_tpu-8\",\n",
        "        \"url\": \"http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_resnet152_v1_fpn_1024x1024_coco17_tpu-8.tar.gz\",\n",
        "    },\n",
        "    \"faster_rcnn_resnet50_v1_640x640_coco17_tpu\": {\n",
        "        \"name\": \"Faster\\ R-CNN\\ ResNet50\\ V1\",\n",
        "        \"input\": (640, 640),\n",
        "        \"extract_dir\": \"faster_rcnn_resnet50_v1_640x640_coco17_tpu-8\",\n",
        "        \"url\": \"http://download.tensorflow.org/models/object_detection/tf2/20200711/faster_rcnn_resnet50_v1_640x640_coco17_tpu-8.tar.gz\",\n",
        "    },\n",
        "    \"faster_rcnn_resnet50_v1_1024x1024_coco17_tpu\": {\n",
        "        \"name\": \"Faster\\ R-CNN\\ ResNet50\\ V1\",\n",
        "        \"input\": (1024, 1024),\n",
        "        \"extract_dir\": \"faster_rcnn_resnet50_v1_1024x1024_coco17_tpu-8\",\n",
        "        \"url\": \"http://download.tensorflow.org/models/object_detection/tf2/20200711/faster_rcnn_resnet50_v1_1024x1024_coco17_tpu-8.tar.gz\",\n",
        "    },\n",
        "    \"faster_rcnn_resnet50_v1_800x1333_coco17_gpu\": {\n",
        "        \"name\": \"Faster\\ R-CNN\\ ResNet50\\ V1\",\n",
        "        \"input\": (800, 1333),\n",
        "        \"extract_dir\": \"faster_rcnn_resnet50_v1_800x1333_coco17_gpu-8\",\n",
        "        \"url\": \"http://download.tensorflow.org/models/object_detection/tf2/20200711/faster_rcnn_resnet50_v1_800x1333_coco17_gpu-8.tar.gz\",\n",
        "    },\n",
        "    \"faster_rcnn_resnet101_v1_640x640_coco17_tpu\": {\n",
        "        \"name\": \"Faster\\ R-CNN\\ ResNet101\\ V1\",\n",
        "        \"input\": (640, 640),\n",
        "        \"extract_dir\": \"faster_rcnn_resnet101_v1_640x640_coco17_tpu-8\",\n",
        "        \"url\": \"http://download.tensorflow.org/models/object_detection/tf2/20200711/faster_rcnn_resnet101_v1_640x640_coco17_tpu-8.tar.gz\",\n",
        "    },\n",
        "    \"faster_rcnn_resnet101_v1_1024x1024_coco17_tpu\": {\n",
        "        \"name\": \"Faster\\ R-CNN\\ ResNet101\\ V1\",\n",
        "        \"input\": (1024, 1024),\n",
        "        \"extract_dir\": \"faster_rcnn_resnet101_v1_1024x1024_coco17_tpu-8\",\n",
        "        \"url\": \"http://download.tensorflow.org/models/object_detection/tf2/20200711/faster_rcnn_resnet101_v1_1024x1024_coco17_tpu-8.tar.gz\",\n",
        "    },\n",
        "    \"faster_rcnn_resnet101_v1_800x1333_coco17_gpu\": {\n",
        "        \"name\": \"Faster\\ R-CNN\\ ResNet101\\ V1\",\n",
        "        \"input\": (800, 1333),\n",
        "        \"extract_dir\": \"faster_rcnn_resnet101_v1_800x1333_coco17_gpu-8\",\n",
        "        \"url\": \"http://download.tensorflow.org/models/object_detection/tf2/20200711/faster_rcnn_resnet101_v1_800x1333_coco17_gpu-8.tar.gz\",\n",
        "    },\n",
        "    \"faster_rcnn_resnet152_v1_640x640_coco17_tpu\": {\n",
        "        \"name\": \"Faster\\ R-CNN\\ ResNet152\\ V1\",\n",
        "        \"input\": (640, 640),\n",
        "        \"extract_dir\": \"faster_rcnn_resnet152_v1_640x640_coco17_tpu-8\",\n",
        "        \"url\": \"http://download.tensorflow.org/models/object_detection/tf2/20200711/faster_rcnn_resnet152_v1_640x640_coco17_tpu-8.tar.gz\",\n",
        "    },\n",
        "    \"faster_rcnn_resnet152_v1_1024x1024_coco17_tpu\": {\n",
        "        \"name\": \"Faster\\ R-CNN\\ ResNet152\\ V1\",\n",
        "        \"input\": (1024, 1024),\n",
        "        \"extract_dir\": \"faster_rcnn_resnet152_v1_1024x1024_coco17_tpu-8\",\n",
        "        \"url\": \"http://download.tensorflow.org/models/object_detection/tf2/20200711/faster_rcnn_resnet152_v1_1024x1024_coco17_tpu-8.tar.gz\",\n",
        "    },\n",
        "    \"faster_rcnn_resnet152_v1_800x1333_coco17_gpu\": {\n",
        "        \"name\": \"Faster\\ R-CNN\\ ResNet152\\ V1\",\n",
        "        \"input\": (800, 1333),\n",
        "        \"extract_dir\": \"faster_rcnn_resnet152_v1_800x1333_coco17_gpu-8\",\n",
        "        \"url\": \"http://download.tensorflow.org/models/object_detection/tf2/20200711/faster_rcnn_resnet152_v1_800x1333_coco17_gpu-8.tar.gz\",\n",
        "    },\n",
        "    \"faster_rcnn_inception_resnet_v2_640x640_coco17_tpu\": {\n",
        "        \"name\": \"Faster\\ R-CNN\\ Inception\\ ResNet\\ V2\",\n",
        "        \"input\": (640, 640),\n",
        "        \"extract_dir\": \"faster_rcnn_inception_resnet_v2_640x640_coco17_tpu-8\",\n",
        "        \"url\": \"http://download.tensorflow.org/models/object_detection/tf2/20200711/faster_rcnn_inception_resnet_v2_640x640_coco17_tpu-8.tar.gz\",\n",
        "    },\n",
        "    \"faster_rcnn_inception_resnet_v2_1024x1024_coco17_tpu\": {\n",
        "        \"name\": \"Faster\\ R-CNN\\ Inception\\ ResNet\\ V2\",\n",
        "        \"input\": (1024, 1024),\n",
        "        \"extract_dir\": \"faster_rcnn_inception_resnet_v2_1024x1024_coco17_tpu-8\",\n",
        "        \"url\": \"http://download.tensorflow.org/models/object_detection/tf2/20200711/faster_rcnn_inception_resnet_v2_1024x1024_coco17_tpu-8.tar.gz\",\n",
        "    },\n",
        "    \"mask_rcnn_inception_resnet_v2_1024x1024_coco17_gpu\": {\n",
        "        \"name\": \"Mask\\ R-CNN\\ Inception\\ ResNet\\ V2\",\n",
        "        \"input\": (1024, 1024),\n",
        "        \"extract_dir\": \"mask_rcnn_inception_resnet_v2_1024x1024_coco17_gpu-8\",\n",
        "        \"url\": \"http://download.tensorflow.org/models/object_detection/tf2/20200711/mask_rcnn_inception_resnet_v2_1024x1024_coco17_gpu-8.tar.gz\",\n",
        "    },\n",
        "    # extremernet\n",
        "    # \"extremenet\": {\n",
        "    #     \"name\": \"ExtremeNet\",\n",
        "    #     \"input\": (, ),\n",
        "    #     \"extract_dir\": \"extremenet\",\n",
        "    #     \"url\": \"http://download.tensorflow.org/models/object_detection/tf2/20200711/extremenet.tar.gz\",\n",
        "    # },\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "c8aqFzJQlHSB"
      },
      "source": [
        "def num_record(path):\n",
        "    return sum([1 for _ in open(path)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "1WmtgBaJr0xL"
      },
      "source": [
        "def output_failed_result(path, name, input, tftrt):\n",
        "    faild_result = [\"\", \"\", \"\", 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
        "    faild_result[0] = name\n",
        "    faild_result[1] = input\n",
        "    faild_result[2] = tftrt\n",
        "    with open(path, 'a') as f:\n",
        "        writer = csv.writer(f)\n",
        "        writer.writerow(faild_result)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "1v1BpMCELAIS"
      },
      "source": [
        "def is_record(path, model_name, width, height):\n",
        "    result = False\n",
        "    model = model_name.replace('\\\\', '')\n",
        "    size = str(height) + \"x\" + str(width)\n",
        "\n",
        "    with open(path) as f:\n",
        "        reader = csv.reader(f)\n",
        "        for row in reader:\n",
        "            if model == row[0].replace('\\\\', '') and size == row[1]:\n",
        "                result = True\n",
        "                break\n",
        "\n",
        "    return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "1HjUjeSHQRY6"
      },
      "source": [
        "def write_header(path):\n",
        "    # write result csv header\n",
        "    header = [\"Model\", \"Input\", \"TF-TRT\",\n",
        "              \"AP\", \"AP50\", \"AP75\", \"APsmall\", \"APmedium\", \"APlarge\",\n",
        "              \"ARmax=1\", \"ARmax=10\", \"ARmax=100\", \"ARsmall\", \"ARmidium\", \"ARlarge\",\n",
        "              \"images/sec\", \"99th_percentile(ms)\", \"total_time(s)\", \"latency_mean(ms)\",\n",
        "              \"latency_median(ms)\", \"latency_min(ms)\"]\n",
        "\n",
        "    with open(path, 'w') as f:\n",
        "        writer = csv.writer(f)\n",
        "        writer.writerow(header)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "oFrKsvoGSR3e"
      },
      "source": [
        "if not os.path.exists(output_path):\n",
        "    print(\"Create result file.\")\n",
        "    write_header(output_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "no7tYYJdZFuP"
      },
      "source": [
        "%cd /content/tensorrt/tftrt/examples/object_detection\n",
        "%pwd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uyDjHsUaWZKC"
      },
      "source": [
        "num_csv_record = 0\n",
        "val2017_dir = \"/content/val2017\"\n",
        "annotations_dir = \"/content/annotations/instances_val2017.json\"\n",
        "input_batch_size = 1\n",
        "display_every = 1000\n",
        "max_workspace_size = 2 * 1024 * 1024 * 1024\n",
        "minimum_segment_size = 20\n",
        "\n",
        "for key in MODELS:\n",
        "    print(\"start --------------------\" + key + \"--------------------\")\n",
        "    url = MODELS[key][\"url\"]\n",
        "    extract_dir = MODELS[key][\"extract_dir\"]\n",
        "    tar_file_name = url.rsplit(\"/\", 1)[1]\n",
        "    input_saved_model_dir = os.path.join(\".\", MODELS[key][\"extract_dir\"], \"saved_model\")\n",
        "    output_dir = os.path.join(\".\", MODELS[key][\"extract_dir\"], \"convert\")\n",
        "    input_height = MODELS[key][\"input\"][0]\n",
        "    input_width = MODELS[key][\"input\"][1]\n",
        "\n",
        "    model_name = MODELS[key][\"name\"]\n",
        "\n",
        "    # check result\n",
        "    if is_record(output_path, model_name, input_width, input_height):\n",
        "        print(\"Already measured. Skip.\")\n",
        "        continue\n",
        "\n",
        "    # download model and extrac file.\n",
        "    if not os.path.exists(tar_file_name):\n",
        "        !wget $url\n",
        "    !tar xf $tar_file_name\n",
        "\n",
        "    # benchmark original model.\n",
        "    print(\"-------------------- Native FP32 model --------------------\")\n",
        "\n",
        "    before_record = num_record(output_path)\n",
        "    output_saved_model_dir = os.path.join(output_dir, \"Native\")\n",
        "    !python object_detection.py \\\n",
        "        --input_saved_model_dir $input_saved_model_dir \\\n",
        "        --output_saved_model_dir $output_saved_model_dir \\\n",
        "        --data_dir $val2017_dir \\\n",
        "        --annotation_path $annotations_dir \\\n",
        "        --batch_size $input_batch_size \\\n",
        "        --input_size $input_height $input_width \\\n",
        "        --display_every $display_every \\\n",
        "        --mode validation \\\n",
        "        --max_workspace_size $max_workspace_size \\\n",
        "        --model_name $model_name \\\n",
        "        --output_csv $output_path\n",
        "\n",
        "    after_record = num_record(output_path)\n",
        "    if before_record == after_record:\n",
        "        # failed benckmark.\n",
        "        output_failed_result(output_path, model_name,\n",
        "                             str(input_height) + \"x\" + str(input_width), \"Native FP32\")\n",
        "    before_record = after_record\n",
        "\n",
        "    if tensor_core_gpu:\n",
        "        # TF-TRT FP32\n",
        "        print(\"-------------------- TF-TRT FP32 model --------------------\")\n",
        "        output_saved_model_dir = os.path.join(output_dir, \"TF_TRT_FP32\")\n",
        "        !python object_detection.py \\\n",
        "            --input_saved_model_dir $input_saved_model_dir \\\n",
        "            --output_saved_model_dir $output_saved_model_dir \\\n",
        "            --data_dir $val2017_dir \\\n",
        "            --annotation_path $annotations_dir \\\n",
        "            --batch_size $input_batch_size \\\n",
        "            --input_size $input_height $input_width \\\n",
        "            --display_every $display_every \\\n",
        "            --mode validation \\\n",
        "            --max_workspace_size $max_workspace_size \\\n",
        "            --minimum_segment_size $minimum_segment_size \\\n",
        "            --model_name $model_name \\\n",
        "            --output_csv $output_path \\\n",
        "            --use_trt \\\n",
        "            --precision FP32 \\\n",
        "            --optimize_offline\n",
        "\n",
        "        after_record = num_record(output_path)\n",
        "        if before_record == after_record:\n",
        "            # failed benckmark.\n",
        "            output_failed_result(output_path, model_name,\n",
        "                                 str(input_height) + \"x\" + str(input_width), \"TF-TRT FP32\")\n",
        "        before_record = after_record\n",
        "\n",
        "        # TF-TRT FP16\n",
        "        print(\"start --------------------\" \"TF-TRT FP16\" \"--------------------\")\n",
        "        output_saved_model_dir = os.path.join(output_dir, \"TF_TRT_FP16\")\n",
        "        !python object_detection.py \\\n",
        "            --input_saved_model_dir $input_saved_model_dir \\\n",
        "            --output_saved_model_dir $output_saved_model_dir \\\n",
        "            --data_dir $val2017_dir \\\n",
        "            --annotation_path $annotations_dir \\\n",
        "            --batch_size $input_batch_size \\\n",
        "            --input_size $input_height $input_width \\\n",
        "            --display_every $display_every \\\n",
        "            --mode validation \\\n",
        "            --minimum_segment_size $minimum_segment_size \\\n",
        "            --max_workspace_size $max_workspace_size \\\n",
        "            --model_name $model_name \\\n",
        "            --output_csv $output_path \\\n",
        "            --use_trt \\\n",
        "            --precision FP16 \\\n",
        "            --optimize_offline\n",
        "\n",
        "        after_record = num_record(output_path)\n",
        "        if before_record == after_record:\n",
        "            # failed benckmark.\n",
        "            output_failed_result(output_path, model_name,\n",
        "                                 str(input_height) + \"x\" + str(input_width), \"TF-TRT FP16\")\n",
        "        before_record = after_record\n",
        "\n",
        "        # TF-TRT INT8\n",
        "        print(\"start --------------------\" \"TF-TRT INT8\" \"--------------------\")\n",
        "        output_saved_model_dir = os.path.join(output_dir, \"TF_TRT_INT8\")\n",
        "        !python object_detection.py \\\n",
        "            --input_saved_model_dir $input_saved_model_dir \\\n",
        "            --output_saved_model_dir $output_saved_model_dir \\\n",
        "            --data_dir $val2017_dir \\\n",
        "            --annotation_path $annotations_dir \\\n",
        "            --batch_size $input_batch_size \\\n",
        "            --input_size $input_height $input_width \\\n",
        "            --display_every $display_every \\\n",
        "            --mode validation \\\n",
        "            --minimum_segment_size $minimum_segment_size \\\n",
        "            --max_workspace_size $max_workspace_size \\\n",
        "            --model_name $model_name \\\n",
        "            --output_csv $output_path \\\n",
        "            --use_trt \\\n",
        "            --precision INT8 \\\n",
        "            --calib_data_dir $val2017_dir \\\n",
        "            --optimize_offline\n",
        "\n",
        "        after_record = num_record(output_path)\n",
        "        if before_record == after_record:\n",
        "            # failed benckmark.\n",
        "            output_failed_result(output_path, model_name,\n",
        "                                 str(input_height) + \"x\" + str(input_width), \"TF-TRT INT8\")\n",
        "        before_record = after_record\n",
        "\n",
        "    # remove dowload and convert model.\n",
        "    !rm -rf $tar_file_name\n",
        "    !rm -rf $extract_dir\n",
        "\n",
        "    # cp result.csv\n",
        "    shutil.copyfile(output_path, output_drive_path)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}